{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-344d77b837af>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t10k-images-idx3-ubyte.gz',\n",
       " 't10k-labels-idx1-ubyte.gz',\n",
       " 'train-images-idx3-ubyte.gz',\n",
       " 'train-labels-idx1-ubyte.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('MNIST/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Inventory\n",
      "---------------\n",
      "Training: 55000\n",
      "Testing: 10000\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "print('Image Inventory')\n",
    "print('---------------')\n",
    "print('Training: ' + str(len(data.train.labels)))\n",
    "print('Testing: ' + str(len(data.test.labels)))\n",
    "print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADhNJREFUeJzt3V2MVPUZx/HfU9Eb9EJZBKKwWGOw1Qslq2kiEo0BoTEBLjS+xNC0ssZoUrQXxZeoCYKmKRa4QddIxER8CbCVGKwa0yBNGsKbUWRBjaFAISyIiRovjO7Tiz00K+75n2HmzJxZnu8nMTszz5yZp9P9cWb2mXP+5u4CEM8vqm4AQDUIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoEa18snMjK8TAk3m7lbL/Rra85vZLDPbZ2afm9miRh4LQGtZvd/tN7OzJH0qaYakQ5K2SbrD3fcktmHPDzRZK/b810r63N2/cPfvJb0maU4DjweghRoJ/0WSDg65fii77SfMrNvMtpvZ9gaeC0DJGvmD33BvLX72tt7deyT1SLztB9pJI3v+Q5ImDrl+saTDjbUDoFUaCf82SZeZ2SVmdo6k2yVtLKctAM1W99t+d//BzB6Q9I6ksyStdvdPSusMQFPVPeqr68n4zA80XUu+5ANg5CL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqLqX6JYkM9sv6RtJP0r6wd27ymgKrdPZ2Zms33PPPcn6o48+mqynVoE2Sy8m29fXl6w/9thjyXpvb2+yHl1D4c/c6O7HS3gcAC3E234gqEbD75LeNbMdZtZdRkMAWqPRt/3XufthM7tQ0ntmttfdPxh6h+wfBf5hANpMQ3t+dz+c/eyX1Cvp2mHu0+PuXfwxEGgvdYffzEab2XknL0uaKWl3WY0BaK5G3vaPk9SbjWtGSVrr7v8opSsATWepOWzpT2bWuicLZOzYsbm1hx9+OLntXXfdlayPGTMmWS+a1Tcy5y/63Tx48GCyfs011+TWjh8/c6fT7p5+YTOM+oCgCD8QFOEHgiL8QFCEHwiK8ANBMeobAYoOm128eHFurej/32aP244dO5asp3R0dCTrkydPTtb37NmTW7viiivqaWlEYNQHIInwA0ERfiAowg8ERfiBoAg/EBThB4Jizj8CbNu2LVmfOnVqbq3ROX9qVi5JN954Y7LeyKGz06ZNS9Y3b96crKf+t48aVcaJq9sTc34ASYQfCIrwA0ERfiAowg8ERfiBoAg/EBRz/jZw+eWXJ+tFc/4vv/wyt1Z0PH3RHP7BBx9M1hcuXJisL126NLd24MCB5LZFin53BwYGcmv33Xdfctuenp66emoHzPkBJBF+ICjCDwRF+IGgCD8QFOEHgiL8QFCFc34zWy3pFkn97n5ldtsFkl6XNFnSfkm3uftXhU/GnL8uRd8DSM3qG12Kuru7O1lftWpVsp5aJnvnzp3JbefNm5esr1u3LllP/W6PHz8+ue1IXsK7zDn/S5JmnXLbIknvu/tlkt7PrgMYQQrD7+4fSDpxys1zJK3JLq+RNLfkvgA0Wb2f+ce5+xFJyn5eWF5LAFqh6ScyM7NuSekPjgBart49/1EzmyBJ2c/+vDu6e4+7d7l7V53PBaAJ6g3/Rknzs8vzJb1ZTjsAWqUw/Gb2qqR/S5piZofM7A+SnpE0w8w+kzQjuw5gBCn8zO/ud+SUbiq5F+TYu3dvZc9ddD6Affv2Jeupcw0UnStg0aL0BLlozYFmfv/hTMA3/ICgCD8QFOEHgiL8QFCEHwiK8ANBnbnrFAcyffr03FrR4cBFo7y+vr5kfcqUKcn61q1bc2tjx45Nblt0uHlR77Nnz07Wo2PPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMec/A9x55525tQULFiS3LTostoZTuyfrqVl+I4fkStLKlSuT9aJTg0fHnh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmLOf4YrmtNXuf2WLVuS2z700EPJOnP8xrDnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCuf8ZrZa0i2S+t39yuy2JyUtkHTyxOmPuPumZjWJtLVr1+bWOjs7k9t2dHQk60Xn/R89enSynvL4448n68zxm6uWPf9LkmYNc/vf3P2q7D+CD4wwheF39w8knWhBLwBaqJHP/A+Y2UdmttrMzi+tIwAtUW/4V0m6VNJVko5IWpZ3RzPrNrPtZra9zucC0AR1hd/dj7r7j+4+IOkFSdcm7tvj7l3u3lVvkwDKV1f4zWzCkKvzJO0upx0ArVLLqO9VSTdI6jCzQ5KekHSDmV0lySXtl3RvE3sE0ATW6PHap/VkZq17MpSiaM7/1FNPJetz587Nre3atSu57ezZs5P1ovP6R+Xu6QURMnzDDwiK8ANBEX4gKMIPBEX4gaAIPxAUo74apZaaPnbsWG4turfffju3dvPNNye3LTp19/Lly+vq6UzHqA9AEuEHgiL8QFCEHwiK8ANBEX4gKMIPBMUS3Znp06cn68uW5Z6pTHv37k1ue/fdd9fV05lgyZIlubWZM2cmt50yZUrZ7WAI9vxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFSYOX/qeHxJeu6555L1/v7+3FrkOX7REt3PP/98bs2spsPO0STs+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqMI5v5lNlPSypPGSBiT1uPsKM7tA0uuSJkvaL+k2d/+qea02Zt68ecl60bHjmzdvLrOdEaNoie7169cn66nXtWjNiKLzJKAxtez5f5D0J3f/laTfSLrfzH4taZGk9939MknvZ9cBjBCF4Xf3I+6+M7v8jaQ+SRdJmiNpTXa3NZLmNqtJAOU7rc/8ZjZZ0tWStkoa5+5HpMF/ICRdWHZzAJqn5u/2m9m5ktZLWujuX9f6vWwz65bUXV97AJqlpj2/mZ2tweC/4u4bspuPmtmErD5B0rBHvrh7j7t3uXtXGQ0DKEdh+G1wF/+ipD53f3ZIaaOk+dnl+ZLeLL89AM1SuES3mU2TtEXSxxoc9UnSIxr83P+GpEmSDki61d1PFDxWZUt0F42s+vr6kvU9e/bk1p5++umGHnvHjh3JepHOzs7c2vXXX5/ctmgEOndu+u+4RR//Ur9fK1asSG5btEQ3hlfrEt2Fn/nd/V+S8h7sptNpCkD74Bt+QFCEHwiK8ANBEX4gKMIPBEX4gaAK5/ylPlmFc/4i69atS9ZT8+5GZt2StGvXrmS9yKRJk3JrY8aMSW7baO9F26eW6F65cmVy2+PHjyfrGF6tc372/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFHP+TNES3ps2bcqtdXWlT1I0MDCQrDdz1l607XfffZesF50+e+nSpcl6b29vso7yMecHkET4gaAIPxAU4QeCIvxAUIQfCIrwA0Ex569RR0dHbm3x4sUNPXZ3d3o1sw0bNiTrjRz3XnTufJbJHnmY8wNIIvxAUIQfCIrwA0ERfiAowg8ERfiBoArn/GY2UdLLksZLGpDU4+4rzOxJSQskHcvu+oi75x/0rpE95wdGilrn/LWEf4KkCe6+08zOk7RD0lxJt0n61t3/WmtThB9ovlrDP6qGBzoi6Uh2+Rsz65N0UWPtAajaaX3mN7PJkq6WtDW76QEz+8jMVpvZ+TnbdJvZdjPb3lCnAEpV83f7zexcSZslLXH3DWY2TtJxSS5psQY/Gvy+4DF42w80WWmf+SXJzM6W9Jakd9z92WHqkyW95e5XFjwO4QearLQDe2zw1LAvSuobGvzsD4EnzZO0+3SbBFCdWv7aP03SFkkfa3DUJ0mPSLpD0lUafNu/X9K92R8HU4/Fnh9oslLf9peF8APNx/H8AJIIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRWewLNkxyX9Z8j1juy2dtSuvbVrXxK91avM3jprvWNLj+f/2ZObbXf3rsoaSGjX3tq1L4ne6lVVb7ztB4Ii/EBQVYe/p+LnT2nX3tq1L4ne6lVJb5V+5gdQnar3/AAqUkn4zWyWme0zs8/NbFEVPeQxs/1m9rGZfVj1EmPZMmj9ZrZ7yG0XmNl7ZvZZ9nPYZdIq6u1JM/tv9tp9aGa/rai3iWb2TzPrM7NPzOyP2e2VvnaJvip53Vr+tt/MzpL0qaQZkg5J2ibpDnff09JGcpjZfkld7l75TNjMpkv6VtLLJ1dDMrO/SDrh7s9k/3Ce7+5/bpPentRprtzcpN7yVpb+nSp87cpc8boMVez5r5X0ubt/4e7fS3pN0pwK+mh77v6BpBOn3DxH0prs8hoN/vK0XE5vbcHdj7j7zuzyN5JOrixd6WuX6KsSVYT/IkkHh1w/pPZa8tslvWtmO8ysu+pmhjHu5MpI2c8LK+7nVIUrN7fSKStLt81rV8+K12WrIvzDrSbSTiOH69x9qqTZku7P3t6iNqskXarBZdyOSFpWZTPZytLrJS1096+r7GWoYfqq5HWrIvyHJE0ccv1iSYcr6GNY7n44+9kvqVeDH1PaydGTi6RmP/sr7uf/3P2ou//o7gOSXlCFr122svR6Sa+4+4bs5spfu+H6qup1qyL82yRdZmaXmNk5km6XtLGCPn7GzEZnf4iRmY2WNFPtt/rwRknzs8vzJb1ZYS8/0S4rN+etLK2KX7t2W/G6ki/5ZKOM5ZLOkrTa3Ze0vIlhmNkvNbi3lwaPeFxbZW9m9qqkGzR41NdRSU9I+rukNyRNknRA0q3u3vI/vOX0doNOc+XmJvWWt7L0VlX42pW54nUp/fANPyAmvuEHBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo/wGTnJDl40xJsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    image = data.train.images[i]\n",
    "    image = np.array(image, dtype = 'float')\n",
    "    label = data.train.labels[i]\n",
    "    pixels = image.reshape((28,28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    print('-------------------')\n",
    "    print(label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('MNIST/images'):\n",
    "    os.mkdir('MNIST/images/')\n",
    "os.chdir('MNIST/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    png = data.train.images[i]\n",
    "    png = np.array(png, dtype = 'float')\n",
    "    pixels = png.reshape((28,28))\n",
    "    image.imsave(\"image_no_{}.png\".format(i),pixels, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_no_1.png', 'image_no_2.png', 'image_no_3.png', 'image_no_4.png', 'image_no_5.png', 'image_no_6.png', 'image_no_7.png', 'image_no_8.png', 'image_no_9.png']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Augmentor import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 9 image(s) found.\n",
      "Output directory set to D:\\spark study\\MNIST\\images\\output."
     ]
    }
   ],
   "source": [
    "augmentor = Pipeline('D:\\spark study\\MNIST\\images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor.rotate(probability=0.9, max_left_rotation=25, max_right_rotation=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGBA size=28x28 at 0x1C4DD412828>: 100%|█| 10/10 [00:00<00:00, 640.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGBA size=28x28 at 0x1C4DD412080>: 100%|█| 10/10 [00:00<00:00, 406.49 Samples/s]               \n"
     ]
    }
   ],
   "source": [
    "for i in range(1,3):\n",
    "    augmentor.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = data.train.images\n",
    "ytrain = np.asarray(data.train.labels)\n",
    "xtest = data.test.images\n",
    "ytest = np.asarray(data.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.reshape(xtrain.shape[0],28,28,1)\n",
    "xtest = xtest.reshape(xtest.shape[0],28,28,1)\n",
    "ytrain = ytrain.reshape(ytrain.shape[0],10)\n",
    "ytest = ytest.reshape(ytest.shape[0],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28, 1)\n",
      "(55000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = (28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - ETA: 53s - loss: 0.6974 - acc: 0.45 - ETA: 38s - loss: 0.5732 - acc: 0.67 - ETA: 31s - loss: 0.4952 - acc: 0.75 - ETA: 28s - loss: 0.4469 - acc: 0.78 - ETA: 26s - loss: 0.4173 - acc: 0.81 - ETA: 24s - loss: 0.3955 - acc: 0.82 - ETA: 23s - loss: 0.3756 - acc: 0.83 - ETA: 22s - loss: 0.3582 - acc: 0.84 - ETA: 21s - loss: 0.3413 - acc: 0.85 - ETA: 20s - loss: 0.3253 - acc: 0.86 - ETA: 20s - loss: 0.3112 - acc: 0.86 - ETA: 19s - loss: 0.2989 - acc: 0.87 - ETA: 19s - loss: 0.2881 - acc: 0.88 - ETA: 18s - loss: 0.2785 - acc: 0.88 - ETA: 17s - loss: 0.2698 - acc: 0.89 - ETA: 17s - loss: 0.2612 - acc: 0.89 - ETA: 16s - loss: 0.2537 - acc: 0.89 - ETA: 16s - loss: 0.2463 - acc: 0.90 - ETA: 15s - loss: 0.2396 - acc: 0.90 - ETA: 14s - loss: 0.2331 - acc: 0.90 - ETA: 14s - loss: 0.2269 - acc: 0.91 - ETA: 13s - loss: 0.2213 - acc: 0.91 - ETA: 13s - loss: 0.2160 - acc: 0.91 - ETA: 12s - loss: 0.2114 - acc: 0.91 - ETA: 12s - loss: 0.2070 - acc: 0.91 - ETA: 12s - loss: 0.2024 - acc: 0.92 - ETA: 11s - loss: 0.1984 - acc: 0.92 - ETA: 11s - loss: 0.1945 - acc: 0.92 - ETA: 10s - loss: 0.1908 - acc: 0.92 - ETA: 10s - loss: 0.1874 - acc: 0.92 - ETA: 9s - loss: 0.1843 - acc: 0.9292 - ETA: 9s - loss: 0.1813 - acc: 0.930 - ETA: 8s - loss: 0.1783 - acc: 0.931 - ETA: 8s - loss: 0.1754 - acc: 0.933 - ETA: 8s - loss: 0.1728 - acc: 0.934 - ETA: 7s - loss: 0.1704 - acc: 0.935 - ETA: 7s - loss: 0.1678 - acc: 0.936 - ETA: 6s - loss: 0.1657 - acc: 0.937 - ETA: 6s - loss: 0.1633 - acc: 0.938 - ETA: 5s - loss: 0.1609 - acc: 0.939 - ETA: 5s - loss: 0.1587 - acc: 0.940 - ETA: 4s - loss: 0.1567 - acc: 0.941 - ETA: 4s - loss: 0.1547 - acc: 0.941 - ETA: 4s - loss: 0.1528 - acc: 0.942 - ETA: 3s - loss: 0.1509 - acc: 0.943 - ETA: 3s - loss: 0.1491 - acc: 0.944 - ETA: 2s - loss: 0.1474 - acc: 0.945 - ETA: 2s - loss: 0.1458 - acc: 0.945 - ETA: 2s - loss: 0.1442 - acc: 0.946 - ETA: 1s - loss: 0.1425 - acc: 0.947 - ETA: 1s - loss: 0.1410 - acc: 0.947 - ETA: 0s - loss: 0.1396 - acc: 0.948 - ETA: 0s - loss: 0.1382 - acc: 0.948 - 24s 437us/step - loss: 0.1373 - acc: 0.9492 - val_loss: 0.0592 - val_acc: 0.9813\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - ETA: 21s - loss: 0.0592 - acc: 0.98 - ETA: 21s - loss: 0.0611 - acc: 0.98 - ETA: 20s - loss: 0.0595 - acc: 0.98 - ETA: 20s - loss: 0.0593 - acc: 0.98 - ETA: 20s - loss: 0.0595 - acc: 0.98 - ETA: 20s - loss: 0.0593 - acc: 0.98 - ETA: 20s - loss: 0.0591 - acc: 0.98 - ETA: 19s - loss: 0.0598 - acc: 0.98 - ETA: 19s - loss: 0.0592 - acc: 0.98 - ETA: 18s - loss: 0.0588 - acc: 0.98 - ETA: 18s - loss: 0.0589 - acc: 0.98 - ETA: 17s - loss: 0.0586 - acc: 0.98 - ETA: 17s - loss: 0.0584 - acc: 0.98 - ETA: 17s - loss: 0.0579 - acc: 0.98 - ETA: 16s - loss: 0.0576 - acc: 0.98 - ETA: 16s - loss: 0.0573 - acc: 0.98 - ETA: 15s - loss: 0.0572 - acc: 0.98 - ETA: 15s - loss: 0.0570 - acc: 0.98 - ETA: 14s - loss: 0.0571 - acc: 0.98 - ETA: 14s - loss: 0.0565 - acc: 0.98 - ETA: 14s - loss: 0.0559 - acc: 0.98 - ETA: 13s - loss: 0.0562 - acc: 0.98 - ETA: 13s - loss: 0.0561 - acc: 0.98 - ETA: 13s - loss: 0.0560 - acc: 0.98 - ETA: 12s - loss: 0.0558 - acc: 0.98 - ETA: 12s - loss: 0.0554 - acc: 0.98 - ETA: 11s - loss: 0.0555 - acc: 0.98 - ETA: 11s - loss: 0.0552 - acc: 0.98 - ETA: 10s - loss: 0.0550 - acc: 0.98 - ETA: 10s - loss: 0.0549 - acc: 0.98 - ETA: 9s - loss: 0.0547 - acc: 0.9825 - ETA: 9s - loss: 0.0546 - acc: 0.982 - ETA: 9s - loss: 0.0544 - acc: 0.982 - ETA: 8s - loss: 0.0542 - acc: 0.982 - ETA: 8s - loss: 0.0540 - acc: 0.982 - ETA: 7s - loss: 0.0539 - acc: 0.982 - ETA: 7s - loss: 0.0537 - acc: 0.983 - ETA: 6s - loss: 0.0535 - acc: 0.983 - ETA: 6s - loss: 0.0532 - acc: 0.983 - ETA: 6s - loss: 0.0530 - acc: 0.983 - ETA: 5s - loss: 0.0530 - acc: 0.983 - ETA: 5s - loss: 0.0527 - acc: 0.983 - ETA: 4s - loss: 0.0524 - acc: 0.983 - ETA: 4s - loss: 0.0522 - acc: 0.983 - ETA: 3s - loss: 0.0520 - acc: 0.983 - ETA: 3s - loss: 0.0518 - acc: 0.983 - ETA: 2s - loss: 0.0516 - acc: 0.983 - ETA: 2s - loss: 0.0514 - acc: 0.983 - ETA: 2s - loss: 0.0513 - acc: 0.983 - ETA: 1s - loss: 0.0511 - acc: 0.983 - ETA: 1s - loss: 0.0510 - acc: 0.983 - ETA: 0s - loss: 0.0507 - acc: 0.984 - ETA: 0s - loss: 0.0505 - acc: 0.984 - 25s 454us/step - loss: 0.0503 - acc: 0.9841 - val_loss: 0.0390 - val_acc: 0.9882\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - ETA: 24s - loss: 0.0362 - acc: 0.98 - ETA: 23s - loss: 0.0370 - acc: 0.98 - ETA: 22s - loss: 0.0372 - acc: 0.98 - ETA: 22s - loss: 0.0376 - acc: 0.98 - ETA: 21s - loss: 0.0388 - acc: 0.98 - ETA: 20s - loss: 0.0386 - acc: 0.98 - ETA: 20s - loss: 0.0383 - acc: 0.98 - ETA: 19s - loss: 0.0376 - acc: 0.98 - ETA: 19s - loss: 0.0374 - acc: 0.98 - ETA: 19s - loss: 0.0376 - acc: 0.98 - ETA: 18s - loss: 0.0376 - acc: 0.98 - ETA: 18s - loss: 0.0374 - acc: 0.98 - ETA: 18s - loss: 0.0372 - acc: 0.98 - ETA: 17s - loss: 0.0372 - acc: 0.98 - ETA: 17s - loss: 0.0372 - acc: 0.98 - ETA: 16s - loss: 0.0372 - acc: 0.98 - ETA: 16s - loss: 0.0373 - acc: 0.98 - ETA: 15s - loss: 0.0367 - acc: 0.98 - ETA: 15s - loss: 0.0368 - acc: 0.98 - ETA: 14s - loss: 0.0369 - acc: 0.98 - ETA: 14s - loss: 0.0368 - acc: 0.98 - ETA: 13s - loss: 0.0368 - acc: 0.98 - ETA: 13s - loss: 0.0365 - acc: 0.98 - ETA: 12s - loss: 0.0364 - acc: 0.98 - ETA: 12s - loss: 0.0364 - acc: 0.98 - ETA: 12s - loss: 0.0364 - acc: 0.98 - ETA: 11s - loss: 0.0363 - acc: 0.98 - ETA: 11s - loss: 0.0362 - acc: 0.98 - ETA: 10s - loss: 0.0359 - acc: 0.98 - ETA: 10s - loss: 0.0360 - acc: 0.98 - ETA: 10s - loss: 0.0360 - acc: 0.98 - ETA: 9s - loss: 0.0360 - acc: 0.9888 - ETA: 9s - loss: 0.0360 - acc: 0.988 - ETA: 8s - loss: 0.0361 - acc: 0.988 - ETA: 8s - loss: 0.0358 - acc: 0.988 - ETA: 7s - loss: 0.0357 - acc: 0.988 - ETA: 7s - loss: 0.0356 - acc: 0.988 - ETA: 6s - loss: 0.0356 - acc: 0.989 - ETA: 6s - loss: 0.0355 - acc: 0.989 - ETA: 6s - loss: 0.0354 - acc: 0.989 - ETA: 5s - loss: 0.0352 - acc: 0.989 - ETA: 5s - loss: 0.0352 - acc: 0.989 - ETA: 4s - loss: 0.0353 - acc: 0.989 - ETA: 4s - loss: 0.0352 - acc: 0.989 - ETA: 3s - loss: 0.0351 - acc: 0.989 - ETA: 3s - loss: 0.0350 - acc: 0.989 - ETA: 2s - loss: 0.0349 - acc: 0.989 - ETA: 2s - loss: 0.0348 - acc: 0.989 - ETA: 2s - loss: 0.0349 - acc: 0.989 - ETA: 1s - loss: 0.0348 - acc: 0.989 - ETA: 1s - loss: 0.0347 - acc: 0.989 - ETA: 0s - loss: 0.0346 - acc: 0.989 - ETA: 0s - loss: 0.0346 - acc: 0.989 - 25s 454us/step - loss: 0.0345 - acc: 0.9894 - val_loss: 0.0289 - val_acc: 0.9911\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - ETA: 24s - loss: 0.0329 - acc: 0.99 - ETA: 24s - loss: 0.0320 - acc: 0.99 - ETA: 24s - loss: 0.0304 - acc: 0.99 - ETA: 24s - loss: 0.0304 - acc: 0.99 - ETA: 23s - loss: 0.0303 - acc: 0.99 - ETA: 22s - loss: 0.0305 - acc: 0.99 - ETA: 21s - loss: 0.0308 - acc: 0.99 - ETA: 21s - loss: 0.0303 - acc: 0.99 - ETA: 20s - loss: 0.0296 - acc: 0.99 - ETA: 19s - loss: 0.0293 - acc: 0.99 - ETA: 19s - loss: 0.0291 - acc: 0.99 - ETA: 18s - loss: 0.0288 - acc: 0.99 - ETA: 18s - loss: 0.0285 - acc: 0.99 - ETA: 17s - loss: 0.0282 - acc: 0.99 - ETA: 17s - loss: 0.0281 - acc: 0.99 - ETA: 16s - loss: 0.0280 - acc: 0.99 - ETA: 16s - loss: 0.0279 - acc: 0.99 - ETA: 15s - loss: 0.0278 - acc: 0.99 - ETA: 15s - loss: 0.0277 - acc: 0.99 - ETA: 15s - loss: 0.0273 - acc: 0.99 - ETA: 14s - loss: 0.0271 - acc: 0.99 - ETA: 14s - loss: 0.0269 - acc: 0.99 - ETA: 13s - loss: 0.0268 - acc: 0.99 - ETA: 13s - loss: 0.0268 - acc: 0.99 - ETA: 12s - loss: 0.0267 - acc: 0.99 - ETA: 12s - loss: 0.0266 - acc: 0.99 - ETA: 11s - loss: 0.0266 - acc: 0.99 - ETA: 11s - loss: 0.0267 - acc: 0.99 - ETA: 10s - loss: 0.0266 - acc: 0.99 - ETA: 10s - loss: 0.0266 - acc: 0.99 - ETA: 10s - loss: 0.0265 - acc: 0.99 - ETA: 9s - loss: 0.0265 - acc: 0.9920 - ETA: 9s - loss: 0.0265 - acc: 0.992 - ETA: 8s - loss: 0.0264 - acc: 0.992 - ETA: 8s - loss: 0.0263 - acc: 0.992 - ETA: 7s - loss: 0.0263 - acc: 0.992 - ETA: 7s - loss: 0.0262 - acc: 0.992 - ETA: 6s - loss: 0.0262 - acc: 0.992 - ETA: 6s - loss: 0.0261 - acc: 0.992 - ETA: 6s - loss: 0.0261 - acc: 0.992 - ETA: 5s - loss: 0.0261 - acc: 0.992 - ETA: 5s - loss: 0.0261 - acc: 0.992 - ETA: 4s - loss: 0.0260 - acc: 0.992 - ETA: 4s - loss: 0.0260 - acc: 0.992 - ETA: 3s - loss: 0.0259 - acc: 0.992 - ETA: 3s - loss: 0.0258 - acc: 0.992 - ETA: 2s - loss: 0.0258 - acc: 0.992 - ETA: 2s - loss: 0.0258 - acc: 0.992 - ETA: 2s - loss: 0.0257 - acc: 0.992 - ETA: 1s - loss: 0.0257 - acc: 0.992 - ETA: 1s - loss: 0.0256 - acc: 0.992 - ETA: 0s - loss: 0.0256 - acc: 0.992 - ETA: 0s - loss: 0.0255 - acc: 0.992 - 25s 455us/step - loss: 0.0254 - acc: 0.9924 - val_loss: 0.0228 - val_acc: 0.9932\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - ETA: 23s - loss: 0.0217 - acc: 0.99 - ETA: 22s - loss: 0.0219 - acc: 0.99 - ETA: 21s - loss: 0.0216 - acc: 0.99 - ETA: 21s - loss: 0.0218 - acc: 0.99 - ETA: 20s - loss: 0.0223 - acc: 0.99 - ETA: 20s - loss: 0.0223 - acc: 0.99 - ETA: 19s - loss: 0.0225 - acc: 0.99 - ETA: 19s - loss: 0.0225 - acc: 0.99 - ETA: 19s - loss: 0.0221 - acc: 0.99 - ETA: 19s - loss: 0.0220 - acc: 0.99 - ETA: 19s - loss: 0.0218 - acc: 0.99 - ETA: 19s - loss: 0.0217 - acc: 0.99 - ETA: 18s - loss: 0.0216 - acc: 0.99 - ETA: 18s - loss: 0.0213 - acc: 0.99 - ETA: 17s - loss: 0.0212 - acc: 0.99 - ETA: 17s - loss: 0.0211 - acc: 0.99 - ETA: 16s - loss: 0.0210 - acc: 0.99 - ETA: 16s - loss: 0.0211 - acc: 0.99 - ETA: 15s - loss: 0.0211 - acc: 0.99 - ETA: 15s - loss: 0.0209 - acc: 0.99 - ETA: 14s - loss: 0.0209 - acc: 0.99 - ETA: 14s - loss: 0.0208 - acc: 0.99 - ETA: 13s - loss: 0.0209 - acc: 0.99 - ETA: 13s - loss: 0.0207 - acc: 0.99 - ETA: 12s - loss: 0.0208 - acc: 0.99 - ETA: 12s - loss: 0.0208 - acc: 0.99 - ETA: 11s - loss: 0.0208 - acc: 0.99 - ETA: 11s - loss: 0.0208 - acc: 0.99 - ETA: 11s - loss: 0.0208 - acc: 0.99 - ETA: 10s - loss: 0.0208 - acc: 0.99 - ETA: 10s - loss: 0.0208 - acc: 0.99 - ETA: 9s - loss: 0.0208 - acc: 0.9937 - ETA: 9s - loss: 0.0208 - acc: 0.993 - ETA: 8s - loss: 0.0208 - acc: 0.993 - ETA: 8s - loss: 0.0207 - acc: 0.993 - ETA: 7s - loss: 0.0207 - acc: 0.993 - ETA: 7s - loss: 0.0206 - acc: 0.993 - ETA: 6s - loss: 0.0207 - acc: 0.993 - ETA: 6s - loss: 0.0205 - acc: 0.993 - ETA: 6s - loss: 0.0204 - acc: 0.993 - ETA: 5s - loss: 0.0203 - acc: 0.993 - ETA: 5s - loss: 0.0204 - acc: 0.993 - ETA: 4s - loss: 0.0204 - acc: 0.993 - ETA: 4s - loss: 0.0203 - acc: 0.993 - ETA: 3s - loss: 0.0203 - acc: 0.993 - ETA: 3s - loss: 0.0204 - acc: 0.993 - ETA: 3s - loss: 0.0204 - acc: 0.993 - ETA: 2s - loss: 0.0203 - acc: 0.993 - ETA: 2s - loss: 0.0203 - acc: 0.994 - ETA: 1s - loss: 0.0203 - acc: 0.994 - ETA: 1s - loss: 0.0203 - acc: 0.994 - ETA: 0s - loss: 0.0202 - acc: 0.994 - ETA: 0s - loss: 0.0202 - acc: 0.994 - 25s 457us/step - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0193 - val_acc: 0.9942\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - ETA: 25s - loss: 0.0168 - acc: 0.99 - ETA: 24s - loss: 0.0166 - acc: 0.99 - ETA: 24s - loss: 0.0172 - acc: 0.99 - ETA: 23s - loss: 0.0170 - acc: 0.99 - ETA: 23s - loss: 0.0165 - acc: 0.99 - ETA: 22s - loss: 0.0169 - acc: 0.99 - ETA: 21s - loss: 0.0173 - acc: 0.99 - ETA: 21s - loss: 0.0169 - acc: 0.99 - ETA: 20s - loss: 0.0171 - acc: 0.99 - ETA: 19s - loss: 0.0168 - acc: 0.99 - ETA: 19s - loss: 0.0169 - acc: 0.99 - ETA: 18s - loss: 0.0167 - acc: 0.99 - ETA: 18s - loss: 0.0168 - acc: 0.99 - ETA: 17s - loss: 0.0169 - acc: 0.99 - ETA: 17s - loss: 0.0167 - acc: 0.99 - ETA: 16s - loss: 0.0168 - acc: 0.99 - ETA: 16s - loss: 0.0170 - acc: 0.99 - ETA: 15s - loss: 0.0169 - acc: 0.99 - ETA: 15s - loss: 0.0169 - acc: 0.99 - ETA: 14s - loss: 0.0171 - acc: 0.99 - ETA: 14s - loss: 0.0170 - acc: 0.99 - ETA: 14s - loss: 0.0170 - acc: 0.99 - ETA: 13s - loss: 0.0171 - acc: 0.99 - ETA: 13s - loss: 0.0171 - acc: 0.99 - ETA: 12s - loss: 0.0169 - acc: 0.99 - ETA: 12s - loss: 0.0169 - acc: 0.99 - ETA: 11s - loss: 0.0169 - acc: 0.99 - ETA: 11s - loss: 0.0169 - acc: 0.99 - ETA: 10s - loss: 0.0168 - acc: 0.99 - ETA: 10s - loss: 0.0169 - acc: 0.99 - ETA: 9s - loss: 0.0168 - acc: 0.9950 - ETA: 9s - loss: 0.0168 - acc: 0.995 - ETA: 9s - loss: 0.0167 - acc: 0.995 - ETA: 8s - loss: 0.0167 - acc: 0.995 - ETA: 8s - loss: 0.0167 - acc: 0.995 - ETA: 7s - loss: 0.0166 - acc: 0.995 - ETA: 7s - loss: 0.0166 - acc: 0.995 - ETA: 6s - loss: 0.0166 - acc: 0.995 - ETA: 6s - loss: 0.0166 - acc: 0.995 - ETA: 6s - loss: 0.0164 - acc: 0.995 - ETA: 5s - loss: 0.0164 - acc: 0.995 - ETA: 5s - loss: 0.0165 - acc: 0.995 - ETA: 4s - loss: 0.0165 - acc: 0.995 - ETA: 4s - loss: 0.0165 - acc: 0.995 - ETA: 3s - loss: 0.0166 - acc: 0.995 - ETA: 3s - loss: 0.0166 - acc: 0.995 - ETA: 2s - loss: 0.0166 - acc: 0.995 - ETA: 2s - loss: 0.0166 - acc: 0.995 - ETA: 2s - loss: 0.0166 - acc: 0.995 - ETA: 1s - loss: 0.0166 - acc: 0.995 - ETA: 1s - loss: 0.0166 - acc: 0.995 - ETA: 0s - loss: 0.0166 - acc: 0.995 - ETA: 0s - loss: 0.0166 - acc: 0.995 - 25s 454us/step - loss: 0.0167 - acc: 0.9951 - val_loss: 0.0175 - val_acc: 0.9946\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - ETA: 22s - loss: 0.0156 - acc: 0.99 - ETA: 22s - loss: 0.0134 - acc: 0.99 - ETA: 22s - loss: 0.0143 - acc: 0.99 - ETA: 21s - loss: 0.0145 - acc: 0.99 - ETA: 21s - loss: 0.0143 - acc: 0.99 - ETA: 20s - loss: 0.0145 - acc: 0.99 - ETA: 20s - loss: 0.0144 - acc: 0.99 - ETA: 19s - loss: 0.0141 - acc: 0.99 - ETA: 19s - loss: 0.0140 - acc: 0.99 - ETA: 19s - loss: 0.0140 - acc: 0.99 - ETA: 18s - loss: 0.0141 - acc: 0.99 - ETA: 18s - loss: 0.0144 - acc: 0.99 - ETA: 18s - loss: 0.0145 - acc: 0.99 - ETA: 17s - loss: 0.0144 - acc: 0.99 - ETA: 17s - loss: 0.0146 - acc: 0.99 - ETA: 16s - loss: 0.0145 - acc: 0.99 - ETA: 16s - loss: 0.0146 - acc: 0.99 - ETA: 15s - loss: 0.0147 - acc: 0.99 - ETA: 15s - loss: 0.0146 - acc: 0.99 - ETA: 15s - loss: 0.0147 - acc: 0.99 - ETA: 14s - loss: 0.0146 - acc: 0.99 - ETA: 14s - loss: 0.0145 - acc: 0.99 - ETA: 13s - loss: 0.0147 - acc: 0.99 - ETA: 13s - loss: 0.0147 - acc: 0.99 - ETA: 12s - loss: 0.0147 - acc: 0.99 - ETA: 12s - loss: 0.0147 - acc: 0.99 - ETA: 11s - loss: 0.0147 - acc: 0.99 - ETA: 11s - loss: 0.0148 - acc: 0.99 - ETA: 11s - loss: 0.0147 - acc: 0.99 - ETA: 10s - loss: 0.0146 - acc: 0.99 - ETA: 10s - loss: 0.0145 - acc: 0.99 - ETA: 9s - loss: 0.0145 - acc: 0.9958 - ETA: 9s - loss: 0.0144 - acc: 0.995 - ETA: 8s - loss: 0.0144 - acc: 0.995 - ETA: 8s - loss: 0.0144 - acc: 0.995 - ETA: 7s - loss: 0.0144 - acc: 0.995 - ETA: 7s - loss: 0.0144 - acc: 0.995 - ETA: 7s - loss: 0.0144 - acc: 0.995 - ETA: 6s - loss: 0.0144 - acc: 0.995 - ETA: 6s - loss: 0.0144 - acc: 0.995 - ETA: 5s - loss: 0.0143 - acc: 0.995 - ETA: 5s - loss: 0.0143 - acc: 0.995 - ETA: 4s - loss: 0.0142 - acc: 0.995 - ETA: 4s - loss: 0.0142 - acc: 0.995 - ETA: 3s - loss: 0.0143 - acc: 0.995 - ETA: 3s - loss: 0.0142 - acc: 0.995 - ETA: 3s - loss: 0.0143 - acc: 0.995 - ETA: 2s - loss: 0.0143 - acc: 0.995 - ETA: 2s - loss: 0.0143 - acc: 0.995 - ETA: 1s - loss: 0.0143 - acc: 0.995 - ETA: 1s - loss: 0.0143 - acc: 0.995 - ETA: 0s - loss: 0.0143 - acc: 0.995 - ETA: 0s - loss: 0.0143 - acc: 0.995 - 25s 463us/step - loss: 0.0142 - acc: 0.9958 - val_loss: 0.0154 - val_acc: 0.9950\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - ETA: 26s - loss: 0.0153 - acc: 0.99 - ETA: 25s - loss: 0.0150 - acc: 0.99 - ETA: 24s - loss: 0.0153 - acc: 0.99 - ETA: 24s - loss: 0.0144 - acc: 0.99 - ETA: 22s - loss: 0.0140 - acc: 0.99 - ETA: 22s - loss: 0.0133 - acc: 0.99 - ETA: 21s - loss: 0.0136 - acc: 0.99 - ETA: 20s - loss: 0.0136 - acc: 0.99 - ETA: 20s - loss: 0.0133 - acc: 0.99 - ETA: 19s - loss: 0.0133 - acc: 0.99 - ETA: 19s - loss: 0.0131 - acc: 0.99 - ETA: 18s - loss: 0.0130 - acc: 0.99 - ETA: 18s - loss: 0.0129 - acc: 0.99 - ETA: 17s - loss: 0.0127 - acc: 0.99 - ETA: 17s - loss: 0.0125 - acc: 0.99 - ETA: 16s - loss: 0.0125 - acc: 0.99 - ETA: 16s - loss: 0.0123 - acc: 0.99 - ETA: 16s - loss: 0.0123 - acc: 0.99 - ETA: 15s - loss: 0.0123 - acc: 0.99 - ETA: 15s - loss: 0.0122 - acc: 0.99 - ETA: 14s - loss: 0.0122 - acc: 0.99 - ETA: 14s - loss: 0.0122 - acc: 0.99 - ETA: 13s - loss: 0.0122 - acc: 0.99 - ETA: 13s - loss: 0.0122 - acc: 0.99 - ETA: 12s - loss: 0.0122 - acc: 0.99 - ETA: 12s - loss: 0.0121 - acc: 0.99 - ETA: 11s - loss: 0.0122 - acc: 0.99 - ETA: 11s - loss: 0.0122 - acc: 0.99 - ETA: 11s - loss: 0.0123 - acc: 0.99 - ETA: 10s - loss: 0.0123 - acc: 0.99 - ETA: 10s - loss: 0.0124 - acc: 0.99 - ETA: 9s - loss: 0.0124 - acc: 0.9962 - ETA: 9s - loss: 0.0124 - acc: 0.996 - ETA: 8s - loss: 0.0124 - acc: 0.996 - ETA: 8s - loss: 0.0123 - acc: 0.996 - ETA: 8s - loss: 0.0124 - acc: 0.996 - ETA: 7s - loss: 0.0123 - acc: 0.996 - ETA: 7s - loss: 0.0123 - acc: 0.996 - ETA: 6s - loss: 0.0123 - acc: 0.996 - ETA: 6s - loss: 0.0124 - acc: 0.996 - ETA: 5s - loss: 0.0124 - acc: 0.996 - ETA: 5s - loss: 0.0124 - acc: 0.996 - ETA: 4s - loss: 0.0124 - acc: 0.996 - ETA: 4s - loss: 0.0124 - acc: 0.996 - ETA: 3s - loss: 0.0124 - acc: 0.996 - ETA: 3s - loss: 0.0124 - acc: 0.996 - ETA: 3s - loss: 0.0124 - acc: 0.996 - ETA: 2s - loss: 0.0123 - acc: 0.996 - ETA: 2s - loss: 0.0123 - acc: 0.996 - ETA: 1s - loss: 0.0123 - acc: 0.996 - ETA: 1s - loss: 0.0123 - acc: 0.996 - ETA: 0s - loss: 0.0123 - acc: 0.996 - ETA: 0s - loss: 0.0124 - acc: 0.996 - 26s 464us/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0142 - val_acc: 0.9953\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - ETA: 24s - loss: 0.0091 - acc: 0.99 - ETA: 23s - loss: 0.0089 - acc: 0.99 - ETA: 22s - loss: 0.0098 - acc: 0.99 - ETA: 21s - loss: 0.0099 - acc: 0.99 - ETA: 21s - loss: 0.0105 - acc: 0.99 - ETA: 20s - loss: 0.0102 - acc: 0.99 - ETA: 20s - loss: 0.0102 - acc: 0.99 - ETA: 20s - loss: 0.0101 - acc: 0.99 - ETA: 20s - loss: 0.0104 - acc: 0.99 - ETA: 19s - loss: 0.0103 - acc: 0.99 - ETA: 19s - loss: 0.0105 - acc: 0.99 - ETA: 18s - loss: 0.0106 - acc: 0.99 - ETA: 18s - loss: 0.0106 - acc: 0.99 - ETA: 17s - loss: 0.0109 - acc: 0.99 - ETA: 17s - loss: 0.0107 - acc: 0.99 - ETA: 16s - loss: 0.0107 - acc: 0.99 - ETA: 16s - loss: 0.0108 - acc: 0.99 - ETA: 15s - loss: 0.0109 - acc: 0.99 - ETA: 15s - loss: 0.0109 - acc: 0.99 - ETA: 14s - loss: 0.0108 - acc: 0.99 - ETA: 14s - loss: 0.0107 - acc: 0.99 - ETA: 14s - loss: 0.0107 - acc: 0.99 - ETA: 13s - loss: 0.0106 - acc: 0.99 - ETA: 13s - loss: 0.0105 - acc: 0.99 - ETA: 12s - loss: 0.0105 - acc: 0.99 - ETA: 12s - loss: 0.0105 - acc: 0.99 - ETA: 12s - loss: 0.0106 - acc: 0.99 - ETA: 11s - loss: 0.0106 - acc: 0.99 - ETA: 11s - loss: 0.0106 - acc: 0.99 - ETA: 10s - loss: 0.0105 - acc: 0.99 - ETA: 10s - loss: 0.0105 - acc: 0.99 - ETA: 9s - loss: 0.0105 - acc: 0.9970 - ETA: 9s - loss: 0.0105 - acc: 0.997 - ETA: 8s - loss: 0.0105 - acc: 0.997 - ETA: 8s - loss: 0.0105 - acc: 0.997 - ETA: 7s - loss: 0.0105 - acc: 0.997 - ETA: 7s - loss: 0.0105 - acc: 0.997 - ETA: 7s - loss: 0.0105 - acc: 0.997 - ETA: 6s - loss: 0.0105 - acc: 0.997 - ETA: 6s - loss: 0.0106 - acc: 0.996 - ETA: 5s - loss: 0.0106 - acc: 0.996 - ETA: 5s - loss: 0.0107 - acc: 0.996 - ETA: 4s - loss: 0.0107 - acc: 0.996 - ETA: 4s - loss: 0.0108 - acc: 0.996 - ETA: 3s - loss: 0.0109 - acc: 0.996 - ETA: 3s - loss: 0.0108 - acc: 0.996 - ETA: 3s - loss: 0.0108 - acc: 0.996 - ETA: 2s - loss: 0.0108 - acc: 0.996 - ETA: 2s - loss: 0.0108 - acc: 0.996 - ETA: 1s - loss: 0.0108 - acc: 0.996 - ETA: 1s - loss: 0.0108 - acc: 0.996 - ETA: 0s - loss: 0.0108 - acc: 0.996 - ETA: 0s - loss: 0.0108 - acc: 0.996 - 26s 465us/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.0135 - val_acc: 0.9956\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - ETA: 23s - loss: 0.0092 - acc: 0.99 - ETA: 23s - loss: 0.0081 - acc: 0.99 - ETA: 22s - loss: 0.0077 - acc: 0.99 - ETA: 21s - loss: 0.0087 - acc: 0.99 - ETA: 21s - loss: 0.0093 - acc: 0.99 - ETA: 20s - loss: 0.0094 - acc: 0.99 - ETA: 20s - loss: 0.0094 - acc: 0.99 - ETA: 19s - loss: 0.0094 - acc: 0.99 - ETA: 19s - loss: 0.0093 - acc: 0.99 - ETA: 19s - loss: 0.0091 - acc: 0.99 - ETA: 18s - loss: 0.0092 - acc: 0.99 - ETA: 18s - loss: 0.0092 - acc: 0.99 - ETA: 18s - loss: 0.0091 - acc: 0.99 - ETA: 17s - loss: 0.0092 - acc: 0.99 - ETA: 17s - loss: 0.0092 - acc: 0.99 - ETA: 17s - loss: 0.0091 - acc: 0.99 - ETA: 16s - loss: 0.0092 - acc: 0.99 - ETA: 16s - loss: 0.0094 - acc: 0.99 - ETA: 15s - loss: 0.0093 - acc: 0.99 - ETA: 15s - loss: 0.0095 - acc: 0.99 - ETA: 14s - loss: 0.0096 - acc: 0.99 - ETA: 14s - loss: 0.0095 - acc: 0.99 - ETA: 13s - loss: 0.0095 - acc: 0.99 - ETA: 13s - loss: 0.0095 - acc: 0.99 - ETA: 12s - loss: 0.0095 - acc: 0.99 - ETA: 12s - loss: 0.0094 - acc: 0.99 - ETA: 11s - loss: 0.0094 - acc: 0.99 - ETA: 11s - loss: 0.0094 - acc: 0.99 - ETA: 11s - loss: 0.0094 - acc: 0.99 - ETA: 10s - loss: 0.0094 - acc: 0.99 - ETA: 10s - loss: 0.0094 - acc: 0.99 - ETA: 9s - loss: 0.0094 - acc: 0.9973 - ETA: 9s - loss: 0.0094 - acc: 0.997 - ETA: 8s - loss: 0.0095 - acc: 0.997 - ETA: 8s - loss: 0.0095 - acc: 0.997 - ETA: 7s - loss: 0.0096 - acc: 0.997 - ETA: 7s - loss: 0.0095 - acc: 0.997 - ETA: 7s - loss: 0.0095 - acc: 0.997 - ETA: 6s - loss: 0.0095 - acc: 0.997 - ETA: 6s - loss: 0.0096 - acc: 0.997 - ETA: 5s - loss: 0.0096 - acc: 0.997 - ETA: 5s - loss: 0.0097 - acc: 0.997 - ETA: 4s - loss: 0.0096 - acc: 0.997 - ETA: 4s - loss: 0.0096 - acc: 0.997 - ETA: 3s - loss: 0.0096 - acc: 0.997 - ETA: 3s - loss: 0.0096 - acc: 0.997 - ETA: 3s - loss: 0.0096 - acc: 0.997 - ETA: 2s - loss: 0.0096 - acc: 0.997 - ETA: 2s - loss: 0.0096 - acc: 0.997 - ETA: 1s - loss: 0.0096 - acc: 0.997 - ETA: 1s - loss: 0.0096 - acc: 0.997 - ETA: 0s - loss: 0.0096 - acc: 0.997 - ETA: 0s - loss: 0.0096 - acc: 0.997 - 26s 465us/step - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0128 - val_acc: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4dd8279e8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain,batch_size = 1024, epochs = 10, validation_data = (xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 3s 296us/step\n"
     ]
    }
   ],
   "source": [
    "stats = model.evaluate(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate is 99.6%\n",
      "The loss rate is 1.3%\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy rate is {}%\".format(round(stats[1],3)*100))\n",
    "print(\"The loss rate is {}%\".format(round(stats[0],3)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               2769024   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,770,634\n",
      "Trainable params: 2,770,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
